\part{Introduction}


\chapter{Overview}

\noindent
This document is both a user's guide and a reference manual for
\Stan's probabilistic modeling language.  This introductory chapter
provides a high-level overview of \Stan. The remaining
parts of this document include a practically-oriented user's guide for
programming models and a detailed reference manual for \Stan's
modeling language and associated programs and data formats.

\section{Stan Home Page}

For links to up-to-date code, examples, manuals, bug reports,
feature requests, and everything else Stan related, see
the Stan home page:
%
\begin{quote}
\url{http://mc-stan.org/}
\end{quote}


\section{Stan Interfaces}

There are three interfaces for Stan that are supported as part of the
Stan project.  Models and their use are the same across the three
interfaces, and this manual is the modeling language manual for all
three interfaces.  All of the interfaces share initialization,
sampling and tuning controls, and roughly share posterior analysis
functionality.   

\subsection{CmdStan}

CmdStan allows Stan to be run from the command line.  In some sense,
CmdStan is the reference implementation of Stan.  The CmdStan
documentation used to be part of this document, but is now its own
standalone document.  The CmdStan home page, with links to download
and installation instructions and the manual is code and manual is
%
\begin{quote}
\url{http://mc-stan.org/cmdstan.html}
\end{quote}

\subsection{RStan}

RStan is the R interface to Stan.  RStan interfaces to Stan through
R's memory rather than just calling Stan from the outside, as in the
R2WinBUGS and R2jags interfaces on which it was modeled.  The RStan
home page, with links to download and installation instructions and the 
manual is
%
\begin{quote}
\url{http://mc-stan.org/rstan.html}
\end{quote}

\subsection{PyStan}

PyStan is the Python interface to Stan.  Like RStan, it interfaces at
the Python memory level rather than calling Stan from the outside.
The PyStan home page, with links to download and installation
instructions and the manual is
%
\begin{quote}
\url{http://mc-stan.org/pystan.html}
\end{quote}


\subsection{Future Interfaces}

Work is underway to develop interfaces for Stan in:
%
\begin{itemize}
\item MATLAB
\item Julia
\item Stata
\end{itemize}
%
For more information, or to get involved in the design or coding, see
the Stan message groups at
%
\begin{quote}
\url{http://mc-stan.org/groups.html}
\end{quote}


\section{Stan Programs}

A \Stan program defines a statistical model through a conditional
probability function $p(\theta|y;x)$, where $\theta$ is a sequence of
modeled unknown values (e.g., model parameters, latent variables, missing
data, future predictions), $y$ is a sequence of modeled known 
values, and $x$ is a sequence of unmodeled predictors and constants
(e.g., sizes, hyperparameters).

\Stan programs consist of variable type declarations and statements.
Variable types include constrained and unconstrained integer, scalar,
vector, and matrix types, as well as (multidimensional) arrays of
other types.  Variables are declared in blocks corresponding to the
variable's use: data, transformed data, parameter, transformed
parameter, or generated quantity.  Unconstrained local variables may
be declared within statement blocks.

Statements in \Stan are interpreted imperatively, so their order
matters.  Atomic statements involve the assignment of a value to a
variable.  Sequences of statements (and optionally local variable
declarations) may be organized into a block.  \Stan also provides bounded
for-each loops of the sort used in \R and \BUGS.

The transformed data, transformed parameter, and generated quantities
blocks contain statements defining the variables declared in their
blocks.  A special model block consists of statements defining the log
probability for the model.

Within the model block, \BUGS-style sampling notation may be used as
shorthand for incrementing an underlying log probability variable, the
value of which defines the log probability function.  The log
probability variable may also be accessed directly, allowing
user-defined probability functions and Jacobians of transforms.


\section{Compiling and Running \Stan Programs}

A \Stan program is first compiled to a \Cpp program by the \Stan
compiler \stanc, then the \Cpp program compiled to a self-contained
platform-specific executable.  \Stan can generate executables for
various flavors of Windows, Mac OS X, and Linux.%
%
\footnote{A \Stan program may also be compiled to a dynamically
  linkable object file for use in a higher-level scripting language
  such as \R or Python.}
%
Running the \Stan executable for a model first reads in and validates
the known values $y$ and $x$, then generates a sequence of
(non-independent) identically distributed samples $\theta^{(1)},
\theta^{(2)}, \ldots$, each of which has the marginal distribution
$p(\theta|y;x)$.


\section{Sampling}

For continuous parameters, \Stan uses Hamiltonian Monte Carlo (\HMC)
sampling \citep{Duane:1987, Neal:1994, Neal:2011}, a form of Markov chain Monte
Carlo (\MCMC) sampling \citep{Metropolis:1953}.  \Stan 1.0 does not do
discrete sampling.%
%
\footnote{Plans are in place to add full discrete sampling in \Stan
  2.0.  An intermediate step will be to allow forward sampling of
  discrete variables in the generated quantities block for predictive
  modeling and model checking.}
%
\refchapter{mixture-modeling} discusses how finite discrete parameters
can be summed out of models.

\HMC accelerates both convergence to the stationary distribution and
subsequent parameter exploration by using the gradient of the log
probability function.  The unknown quantity vector $\theta$ is
interpreted as the position of a fictional particle.  Each iteration
generates a random momentum and simulates the path of the particle
with potential energy determined the (negative) log probability
function.  Hamilton's decomposition shows that the gradient of this
potential determines change in momentum and the momentum determines
the change in position.  These continuous changes over time are
approximated using the leapfrog algorithm, which breaks the time into
discrete steps which are easily simulated.  A Metropolis reject step
is then applied to correct for any simulation error and ensure
detailed balance of the resulting Markov chain transitions
\citep{Metropolis:1953, Hastings:1970}.

Standard \HMC involves three ``tuning'' parameters to which its
behavior is quite sensitive.  \Stan's samplers allow these parameters
to be set by hand or set automatically without user intervention.

The first two tuning parameters set the temporal step size of the
discretization of the Hamiltonian and the total number of steps taken
per iteration (with their product determining total simulation time).
\Stan can be configured with a user-specified step size or it can
estimate an optimal step size during warmup using dual averaging
\citep{Nesterov:2009, Hoffman-Gelman:2011, Hoffman-Gelman:2014}.  
In either case, additional randomization may be applied to draw the 
step size from an interval of possible step sizes \citep{Neal:2011}.

\Stan can be set to use a specified number of steps, or it can
automatically adapt the number of steps during sampling using the
No-U-Turn (\NUTS) sampler 
\citep{Hoffman-Gelman:2011, Hoffman-Gelman:2014}.  

The third tuning parameter is a mass matrix for the fictional
particle.  \Stan can be configured to estimate a diagonal mass matrix
or a full mass matrix during warmup; Stan will support user-specified
mass matrices in the future.  Estimating a diagonal mass matrix
normalizes the scale of each element $\theta_k$ of the unknown
variable sequence $\theta$, whereas estimating a full mass matrix
accounts for both scaling and rotation,%
%
\footnote{These estimated mass matrices are global, meaning they are
  applied to every point in the parameter space being sampled.
  Riemann-manifold HMC generalizes this to allow the curvature implied
  by the mass matrix to vary by position.}
%
but is more memory and computation intensive per leapfrog step due to
the underlying matrix operations.

\subsection{Convergence Monitoring and Effective Sample Size}

Samples in a Markov chain are only drawn with the marginal
distribution $p(\theta|y;x)$ after the chain has converged to its
equilibrium distribution.  There are several methods to test whether
an \MCMC method has failed to converge; unfortunately, passing the
tests does not guarantee convergence.  The recommended method for
\Stan is to run multiple Markov chains each with different diffuse
initial parameter values, discard the warmup/adaptation samples, then
split the remainder of each chain in half and compute the potential
scale reduction statistic, $\hat{R}$ \citep{GelmanRubin:1992}.

When estimating a mean based on $M$ independent samples, the
estimation error is proportional to $1/\sqrt{M}$.  If the samples are
positively correlated, as they typically are when drawn using \MCMC
methods, the error is proportional to $1/\sqrt{\mbox{\sc ess}}$, where
{\sc ess} is the effective sample size.  Thus it is standard practice
to also monitor (an estimate of) the effective sample size of
parameters of interest in order to estimate the additional estimation
error due to correlated samples.

\subsection{Bayesian Inference and Monte Carlo Methods}

\Stan was developed to support full Bayesian inference.  Bayesian
inference is based in part on Bayes's rule,
\[
p(\theta|y;x) \propto p(y|\theta;x) \, p(\theta;x),
\]
which, in this unnormalized form, states that the posterior
probability $p(\theta|y;x)$ of parameters $\theta$ given data $y$ (and
constants $x$) is proportional (for fixed $y$ and $x$) to the
product of the likelihood function $p(y|\theta;x)$ and prior
$p(\theta;x)$.

For \Stan, Bayesian modeling involves coding the posterior probability
function up to a proportion, which Bayes's rule shows is equivalent to
modeling the product of the likelihood function and prior up to a
proportion.

Full Bayesian inference involves propagating the uncertainty in the
value of parameters $\theta$ modeled by the posterior $p(\theta|y;x)$.
This can be accomplished by basing inference on a sequence of samples
from the posterior using plug-in estimates for quantities of interest
such as posterior means, posterior intervals, predictions based on the
posterior such as event outcomes or the values of as yet unobserved
data.


\section{Optimization}

\Stan also supports optimization-based inference for models.  Given a
posterior $p(\theta|y)$, Stan can find the posterior mode $\theta^*$,
which is defined by
%
\[
\theta^{*} = \mbox{argmax}_{\theta} \ p(\theta|y).
\]
%
Here the notation $\mbox{argmax}_u \ f(v)$ is used to pick out the value
of $v$ at which $f(v)$ is maximized.  

If the prior is uniform, the posterior mode corresponds to the maximum
likelihood estimate (MLE) of the parameters.  If the prior is not
uniform, the posterior mode is sometimes called the maximum a
posterior (MAP) estimate.  If parameters (typically hierarchical) have
been marginalized out, it's sometimes called a maximum marginal
likelihood (MML) estimate. 


\subsection{Inference with Point Estimates}

The estimate $\theta^{*}$ is a so-called ``point estimate,'' meaning
that it summarizes the posterior distribution by a single point,
rather than with a distribution.  Of course, a point estimate does
not, in and of itself, take into account estimation variance.
Posterior predictive inferences $p(\tilde{y} | y)$ can be made using
the posterior mode given data $y$ as $p(\tilde{y}|\theta^*)$, but they
are not Bayesian inferences, even if the model involves a prior,
because they do not take posterior uncertainty into account.  If the
posterior variance is low and the posterior mean is near the posterior
mode, inference with point estimates can be very similar to full
Bayesian inference.

\subsubsection{``Empirical Bayes''}

Fitting point estimates of priors and then using them for subsequent
inference is sometimes called ``empirical Bayes'' (see, e.g.,
\citep{Efron:2012}).%
%
\footnote{The scare quotes on ``empirical Bayes'' are because the
  approach is no more empirical than full Bayes.  Empirical Bayes
  approaches merely ignore some posterior uncertainty to make
  inference more efficient computationally.}
%
Typically these optimizations will be done using maximum marignal
likelihood rather than posterior modes of a full model.  Sometimes
Empirical Bayes point estimates will be obtained using moment matching
(see, e.g., the rat-tumor example in Chapter 5 of
\citep{GelmanEtAl:2013}).


